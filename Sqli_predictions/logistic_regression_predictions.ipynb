{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./predictions/logistic_regression_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "import joblib\n",
    "\n",
    "# File paths\n",
    "new_logs_csv = './Dataset/converted_sqli.csv'  # Path to the new -logs CSV file\n",
    "model_path = './Models/logistic_regression_model.pkl'      # Path to the trained model (.pkl file)\n",
    "output_csv = './predictions/logistic_regression_prediction.csv'  # Path to save predictions\n",
    "vectorizer_path = './Models/logistic_regression_vectorizer.pkl'\n",
    "scaler_path = './Models/logistic_regression_scaler.pkl'\n",
    "\n",
    "# Step 1: Load the saved components\n",
    "model = joblib.load(model_path)\n",
    "vectorizer = joblib.load(vectorizer_path)\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "# Step 2: Load new logs\n",
    "new_logs = pd.read_csv(new_logs_csv, encoding='latin1', on_bad_lines='skip')\n",
    "new_logs.columns = new_logs.columns.str.strip().str.replace(';', '')\n",
    "\n",
    "# Ensure columns match the expected ones\n",
    "numeric_features = [\n",
    "    'query_len', 'num_words_query', 'no_single_qts', 'no_double_qts', 'no_punct',\n",
    "    'no_single_cmnt', 'no_mult_cmnt', 'no_space', 'no_perc', 'no_log_opt',\n",
    "    'no_arith', 'no_null', 'no_hexa', 'no_alpha', 'no_digit', 'len_of_chr_char_null', 'genuine_keywords'\n",
    "]\n",
    "X_text_new = new_logs['Sentence']\n",
    "X_numeric_new = new_logs[numeric_features]\n",
    "\n",
    "# Step 3: Preprocess new logs\n",
    "# Transform text data\n",
    "X_text_new_tfidf = vectorizer.transform(X_text_new)\n",
    "\n",
    "# Scale numeric features\n",
    "X_numeric_new_scaled = scaler.transform(X_numeric_new)\n",
    "\n",
    "# Combine text and numeric features\n",
    "X_new_combined = hstack([X_text_new_tfidf, X_numeric_new_scaled])\n",
    "\n",
    "# Step 4: Make predictions\n",
    "predictions = model.predict(X_new_combined)\n",
    "\n",
    "# Step 5: Save predictions to a CSV file\n",
    "output = pd.DataFrame({'Prediction': predictions})\n",
    "output.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9723\n",
      "Confusion Matrix:\n",
      "\n",
      "True Negative (TN): 2956\n",
      "False Positive (FP): 33\n",
      "False Negative (FN): 72\n",
      "True Positive (TP): 726\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      2989\n",
      "           1       0.96      0.91      0.93       798\n",
      "\n",
      "    accuracy                           0.97      3787\n",
      "   macro avg       0.97      0.95      0.96      3787\n",
      "weighted avg       0.97      0.97      0.97      3787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score , confusion_matrix\n",
    "\n",
    "# Load the original dataset\n",
    "original_data = pd.read_csv('./Dataset/converted_sqli.csv')  # Replace with your file path\n",
    "\n",
    "# Load the predictions dataset\n",
    "predictions_data = pd.read_csv('./predictions/logistic_regression_prediction.csv')  # Replace with your file path\n",
    "\n",
    "# Ensure the datasets are aligned (e.g., by index)\n",
    "# If the datasets are not aligned, you may need to merge them on a common column\n",
    "# Example: merged_data = pd.merge(original_data, predictions_data, on='common_column')\n",
    "\n",
    "# Extract actual labels (y_true) and predicted labels (y_pred)\n",
    "y_true = original_data['Label']  # Replace 'Label' with the actual column name\n",
    "y_pred = predictions_data['Prediction']  # Replace 'Prediction' with the actual column name\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(f\"True Negative (TN): {TN}\")\n",
    "print(f\"False Positive (FP): {FP}\")\n",
    "print(f\"False Negative (FN): {FN}\")\n",
    "print(f\"True Positive (TP): {TP}\")\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
