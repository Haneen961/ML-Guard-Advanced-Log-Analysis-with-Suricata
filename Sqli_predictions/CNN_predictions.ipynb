{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step\n",
      "Predictions saved to ./predictions/CNN_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import joblib\n",
    "\n",
    "# File paths\n",
    "new_logs_csv = './Dataset/converted_sqli.csv'\n",
    "model_path = './Models/CNN_model.pkl'\n",
    "output_csv = './predictions/CNN_prediction.csv'\n",
    "vectorizer_path = './Models/CNN_vectorizer.pkl'\n",
    "scaler_path = './Models/CNN_scaler.pkl'\n",
    "\n",
    "# Step 1: Load saved components\n",
    "model = joblib.load(model_path)\n",
    "vectorizer = joblib.load(vectorizer_path)\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "# Step 2: Load new logs\n",
    "new_logs = pd.read_csv(new_logs_csv, encoding='latin1', on_bad_lines='skip')\n",
    "new_logs.columns = new_logs.columns.str.strip().str.replace(';', '')\n",
    "\n",
    "# Ensure columns match the expected ones\n",
    "numeric_features = [\n",
    "    'query_len', 'num_words_query', 'no_single_qts', 'no_double_qts', 'no_punct',\n",
    "    'no_single_cmnt', 'no_mult_cmnt', 'no_space', 'no_perc', 'no_log_opt',\n",
    "    'no_arith', 'no_null', 'no_hexa', 'no_alpha', 'no_digit', 'len_of_chr_char_null', 'genuine_keywords'\n",
    "]\n",
    "X_text_new = new_logs['Sentence'].astype(str)  # Ensure it's a string\n",
    "X_numeric_new = new_logs[numeric_features]\n",
    "\n",
    "# Step 3: Preprocess new logs\n",
    "X_text_new_tfidf = vectorizer.transform(X_text_new)\n",
    "X_numeric_new_scaled = scaler.transform(X_numeric_new)\n",
    "\n",
    "# **Fix: Convert sparse to dense and reshape for CNN**\n",
    "X_new_combined = np.hstack([X_text_new_tfidf.toarray(), X_numeric_new_scaled])\n",
    "X_new_combined = X_new_combined.reshape(X_new_combined.shape[0], X_new_combined.shape[1], 1)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "predictions = model.predict(X_new_combined)\n",
    "predicted_labels = np.argmax(predictions, axis=1)  # Convert one-hot to labels\n",
    "\n",
    "# Step 5: Save predictions to CSV\n",
    "output = pd.DataFrame({'Prediction': predicted_labels})\n",
    "output.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9881\n",
      "Confusion Matrix:\n",
      "\n",
      "True Negative (TN): 2969\n",
      "False Positive (FP): 20\n",
      "False Negative (FN): 25\n",
      "True Positive (TP): 773\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2989\n",
      "           1       0.97      0.97      0.97       798\n",
      "\n",
      "    accuracy                           0.99      3787\n",
      "   macro avg       0.98      0.98      0.98      3787\n",
      "weighted avg       0.99      0.99      0.99      3787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score , confusion_matrix\n",
    "\n",
    "# Load the original dataset\n",
    "original_data = pd.read_csv('./Dataset/converted_sqli.csv')  # Replace with your file path\n",
    "\n",
    "# Load the predictions dataset\n",
    "predictions_data = pd.read_csv('./predictions/CNN_prediction.csv')  # Replace with your file path\n",
    "\n",
    "# Ensure the datasets are aligned (e.g., by index)\n",
    "# If the datasets are not aligned, you may need to merge them on a common column\n",
    "# Example: merged_data = pd.merge(original_data, predictions_data, on='common_column')\n",
    "\n",
    "# Extract actual labels (y_true) and predicted labels (y_pred)\n",
    "y_true = original_data['Label']  # Replace 'Label' with the actual column name\n",
    "y_pred = predictions_data['Prediction']  # Replace 'Prediction' with the actual column name\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(f\"True Negative (TN): {TN}\")\n",
    "print(f\"False Positive (FP): {FP}\")\n",
    "print(f\"False Negative (FN): {FN}\")\n",
    "print(f\"True Positive (TP): {TP}\")\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
