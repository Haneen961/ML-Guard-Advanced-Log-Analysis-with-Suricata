{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report , accuracy_score , confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "data = pd.read_csv('/home/saja/algorithms/XSS_enhanced_dataset.csv', encoding='latin1')\n",
    "print(data.head())\n",
    "\n",
    "# Step 2: Preprocess the Data\n",
    "X_text = data['Sentence'].astype(str)  # Ensure text is string format\n",
    "y = data['Label']  # Binary labels (0 = benign, 1 = malicious)\n",
    "\n",
    "# Step 3: Process text data with TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10000)  # Limit vocabulary size\n",
    "X_text_tfidf = vectorizer.fit_transform(X_text)  # Transform queries into TF-IDF vectors\n",
    "\n",
    "# Step 4: Process numerical features\n",
    "numeric_features = data.drop(columns=['Sentence', 'Label'])  # Remove text & target columns\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Step 5: Combine text (TF-IDF) and numerical features\n",
    "X_combined = np.hstack((X_text_tfidf.toarray(), X_numeric_scaled))\n",
    "\n",
    "# Step 6: Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Reshape input for CNN (samples, timesteps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Step 8: Build the Deep Learning Model (CNN with Dense Layers)\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])\n",
    "\n",
    "# Step 9: Compile the Model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 10: Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Step 11: Evaluate the Model\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary\n",
    "\n",
    "# Print Classification Report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(f\"True Negative (TN): {TN}\")\n",
    "print(f\"False Positive (FP): {FP}\")\n",
    "print(f\"False Negative (FN): {FN}\")\n",
    "print(f\"True Positive (TP): {TP}\")\n",
    "\n",
    "\n",
    "# Step 12: Test on New Inputs (SQLi Queries)\n",
    "new_queries = [\n",
    "    \"' AND 1=CONVERT(int, (SELECT @@version)) --\",\n",
    "    \"' OR IF(1=1, SLEEP(5), 0) --\",\n",
    "    \"SELECT * FROM users;\",\n",
    "    \"' AND 1=1 --\"\n",
    "]\n",
    "\n",
    "# Transform new queries using the trained TF-IDF vectorizer\n",
    "X_text_new_tfidf = vectorizer.transform(new_queries)\n",
    "\n",
    "# Assuming no additional numeric features for new queries, use zeros\n",
    "X_numeric_new_scaled = np.zeros((len(new_queries), X_numeric_scaled.shape[1]))\n",
    "\n",
    "# Combine features\n",
    "X_new_combined = np.hstack((X_text_new_tfidf.toarray(), X_numeric_new_scaled))\n",
    "X_new_combined = X_new_combined.reshape(X_new_combined.shape[0], X_new_combined.shape[1], 1)\n",
    "\n",
    "\n",
    "# Predict SQLi vs Safe on new queries\n",
    "new_predictions = model.predict(X_new_combined)\n",
    "\n",
    "# Display predictions\n",
    "for query, pred in zip(new_queries, new_predictions):\n",
    "    print(f\"Sentence: {query}\")\n",
    "    print(\" XSS Detected!\" if pred > 0.5 else \"Query is Safe.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "joblib.dump(model, '/home/saja/algorithms/Models/Deep_Learning_model.pkl')\n",
    "joblib.dump(vectorizer, '/home/saja/algorithms/Models/Deep_Learning_vectorizer.pkl')\n",
    "joblib.dump(scaler, '/home/saja/algorithms/Models/Deep_Learning_scaler.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
